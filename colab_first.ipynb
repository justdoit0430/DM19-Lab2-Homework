{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "colab_first",
      "provenance": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/justdoit0430/DM19-Lab2-Homework/blob/master/colab_first.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0DxXS83rUhin",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W5e7TEmHTN4O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
        "# For example, here's several helpful packages to load in \n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "# Input data files are available in the \"../input/\" directory.\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
        "\n",
        "import os\n",
        "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
        "    for filename in filenames:\n",
        "        print(os.path.join(dirname, filename))\n",
        "\n",
        "# Any results you write to the current directory are saved as output."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TvanB4eJTkwk",
        "colab_type": "code",
        "outputId": "4460e23d-7501-455d-90f9-e2ec58080085",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "import json\n",
        "##with open('/kaggle/input/dm19-lab2-nthu/tweets_DM.json') as json_file:\n",
        "#    json_data = json.load(json_file)\n",
        "    \n",
        "tweets = []\n",
        "for line in open('/content/drive/My Drive/Colab Notebooks/tweets_DM.json', 'r'):\n",
        "    tweets.append(json.loads(line))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bljp20ZEVJGY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pandas.io.json import json_normalize \n",
        "tdf=json_normalize(tweets)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pCzaQUHRVMet",
        "colab_type": "code",
        "outputId": "6c3d65ff-45b8-4313-fb47-88b605b10e15",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 201
        }
      },
      "source": [
        "tdf.rename(columns={'_source.tweet.text': 'text', '_source.tweet.tweet_id': 'tweet_id', '_source.tweet.hashtags':'Hashtags'}, inplace=True)\n",
        "di = pd.read_csv(\"/content/drive/My Drive/Colab Notebooks/data_identification.csv\")\n",
        "emo = pd.read_csv(\"/content/drive/My Drive/Colab Notebooks/emotion.csv\")\n",
        "tdf.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>_score</th>\n",
              "      <th>_index</th>\n",
              "      <th>_crawldate</th>\n",
              "      <th>_type</th>\n",
              "      <th>Hashtags</th>\n",
              "      <th>tweet_id</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>391</td>\n",
              "      <td>hashtag_tweets</td>\n",
              "      <td>2015-05-23 11:42:47</td>\n",
              "      <td>tweets</td>\n",
              "      <td>[Snapchat]</td>\n",
              "      <td>0x376b20</td>\n",
              "      <td>People who post \"add me on #Snapchat\" must be ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>433</td>\n",
              "      <td>hashtag_tweets</td>\n",
              "      <td>2016-01-28 04:52:09</td>\n",
              "      <td>tweets</td>\n",
              "      <td>[freepress, TrumpLegacy, CNN]</td>\n",
              "      <td>0x2d5350</td>\n",
              "      <td>@brianklaas As we see, Trump is dangerous to #...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>232</td>\n",
              "      <td>hashtag_tweets</td>\n",
              "      <td>2017-12-25 04:39:20</td>\n",
              "      <td>tweets</td>\n",
              "      <td>[bibleverse]</td>\n",
              "      <td>0x28b412</td>\n",
              "      <td>Confident of your obedience, I write to you, k...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>376</td>\n",
              "      <td>hashtag_tweets</td>\n",
              "      <td>2016-01-24 23:53:05</td>\n",
              "      <td>tweets</td>\n",
              "      <td>[]</td>\n",
              "      <td>0x1cd5b0</td>\n",
              "      <td>Now ISSA is stalking Tasha üòÇüòÇüòÇ &lt;LH&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>989</td>\n",
              "      <td>hashtag_tweets</td>\n",
              "      <td>2016-01-08 17:18:59</td>\n",
              "      <td>tweets</td>\n",
              "      <td>[]</td>\n",
              "      <td>0x2de201</td>\n",
              "      <td>\"Trust is not the same as faith. A friend is s...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   _score  ...                                               text\n",
              "0     391  ...  People who post \"add me on #Snapchat\" must be ...\n",
              "1     433  ...  @brianklaas As we see, Trump is dangerous to #...\n",
              "2     232  ...  Confident of your obedience, I write to you, k...\n",
              "3     376  ...                Now ISSA is stalking Tasha üòÇüòÇüòÇ <LH>\n",
              "4     989  ...  \"Trust is not the same as faith. A friend is s...\n",
              "\n",
              "[5 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7tCkb-hAVRHZ",
        "colab_type": "code",
        "outputId": "70522140-8858-452d-d589-c7299300958c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 201
        }
      },
      "source": [
        "tdf_merge = tdf.merge(emo, on='tweet_id', how='right')\n",
        "tdf_merge.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>_score</th>\n",
              "      <th>_index</th>\n",
              "      <th>_crawldate</th>\n",
              "      <th>_type</th>\n",
              "      <th>Hashtags</th>\n",
              "      <th>tweet_id</th>\n",
              "      <th>text</th>\n",
              "      <th>emotion</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>391</td>\n",
              "      <td>hashtag_tweets</td>\n",
              "      <td>2015-05-23 11:42:47</td>\n",
              "      <td>tweets</td>\n",
              "      <td>[Snapchat]</td>\n",
              "      <td>0x376b20</td>\n",
              "      <td>People who post \"add me on #Snapchat\" must be ...</td>\n",
              "      <td>anticipation</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>433</td>\n",
              "      <td>hashtag_tweets</td>\n",
              "      <td>2016-01-28 04:52:09</td>\n",
              "      <td>tweets</td>\n",
              "      <td>[freepress, TrumpLegacy, CNN]</td>\n",
              "      <td>0x2d5350</td>\n",
              "      <td>@brianklaas As we see, Trump is dangerous to #...</td>\n",
              "      <td>sadness</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>376</td>\n",
              "      <td>hashtag_tweets</td>\n",
              "      <td>2016-01-24 23:53:05</td>\n",
              "      <td>tweets</td>\n",
              "      <td>[]</td>\n",
              "      <td>0x1cd5b0</td>\n",
              "      <td>Now ISSA is stalking Tasha üòÇüòÇüòÇ &lt;LH&gt;</td>\n",
              "      <td>fear</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>120</td>\n",
              "      <td>hashtag_tweets</td>\n",
              "      <td>2015-06-11 04:44:05</td>\n",
              "      <td>tweets</td>\n",
              "      <td>[authentic, LaughOutLoud]</td>\n",
              "      <td>0x1d755c</td>\n",
              "      <td>@RISKshow @TheKevinAllison Thx for the BEST TI...</td>\n",
              "      <td>joy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1021</td>\n",
              "      <td>hashtag_tweets</td>\n",
              "      <td>2015-08-18 02:30:07</td>\n",
              "      <td>tweets</td>\n",
              "      <td>[]</td>\n",
              "      <td>0x2c91a8</td>\n",
              "      <td>Still waiting on those supplies Liscus. &lt;LH&gt;</td>\n",
              "      <td>anticipation</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   _score  ...       emotion\n",
              "0     391  ...  anticipation\n",
              "1     433  ...       sadness\n",
              "2     376  ...          fear\n",
              "3     120  ...           joy\n",
              "4    1021  ...  anticipation\n",
              "\n",
              "[5 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2B4bfitzVWuJ",
        "colab_type": "code",
        "outputId": "7cae4c6e-7250-42c1-870b-77d65ab5c2c7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "tdf_merge.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1455563, 8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bu_VkkHhVZXS",
        "colab_type": "code",
        "outputId": "cde7cb5d-c6cf-410b-b5a0-b2e0bf9aafc7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        }
      },
      "source": [
        "tdf_train= tdf_merge[['tweet_id', 'text', 'emotion']] \n",
        "print(tdf_train.head())\n",
        "test_merge = di.merge(tdf, on='tweet_id', how='right')\n",
        "test_merge = test_merge[test_merge.identification != 'train']\n",
        "test_merge.loc[:,'emotion'] = ''"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "   tweet_id                                               text       emotion\n",
            "0  0x376b20  People who post \"add me on #Snapchat\" must be ...  anticipation\n",
            "1  0x2d5350  @brianklaas As we see, Trump is dangerous to #...       sadness\n",
            "2  0x1cd5b0                Now ISSA is stalking Tasha üòÇüòÇüòÇ <LH>          fear\n",
            "3  0x1d755c  @RISKshow @TheKevinAllison Thx for the BEST TI...           joy\n",
            "4  0x2c91a8       Still waiting on those supplies Liscus. <LH>  anticipation\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gwfRztvfVcYa",
        "colab_type": "code",
        "outputId": "ff4701b4-a3b4-42cd-f376-954dce73e56c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 201
        }
      },
      "source": [
        "test_merge = test_merge[['tweet_id', 'text', '_type']] \n",
        "test_merge.rename(columns={'_type': 'emotion'}, inplace=True)\n",
        "test_merge.loc[:,'emotion'] = ''\n",
        "test_merge.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweet_id</th>\n",
              "      <th>text</th>\n",
              "      <th>emotion</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0x28cc61</td>\n",
              "      <td>@Habbo I've seen two separate colours of the e...</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0x2db41f</td>\n",
              "      <td>@FoxNews @KellyannePolls No serious self respe...</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>0x2466f6</td>\n",
              "      <td>Looking for a new car, and it says 1 lady owne...</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>0x23f9e9</td>\n",
              "      <td>@cineworld ‚Äúonly the brave‚Äù just out and fount...</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>0x1fb4e1</td>\n",
              "      <td>Felt like total dog üí© going into open gym and ...</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    tweet_id                                               text emotion\n",
              "0   0x28cc61  @Habbo I've seen two separate colours of the e...        \n",
              "3   0x2db41f  @FoxNews @KellyannePolls No serious self respe...        \n",
              "15  0x2466f6  Looking for a new car, and it says 1 lady owne...        \n",
              "23  0x23f9e9  @cineworld ‚Äúonly the brave‚Äù just out and fount...        \n",
              "31  0x1fb4e1  Felt like total dog üí© going into open gym and ...        "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bnwdi4c-V9Ke",
        "colab_type": "code",
        "outputId": "42eb4434-4a4f-4b52-d31a-50c75e02e368",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 439
        }
      },
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "import string\n",
        "import re\n",
        "from ipykernel import kernelapp as app\n",
        "import sys\n",
        "string.punctuation\n",
        "def remove_punct(text):\n",
        "    text  = \"\".join([char for char in text if char not in string.punctuation])\n",
        "    text = re.sub('[0-9]+', '', text)\n",
        "    return text\n",
        "\n",
        "tdf_train['Tweet_punct'] = tdf_train['text'].apply(lambda x: remove_punct(x))\n",
        "string.punctuation\n",
        "\n",
        "def tokenization(text):\n",
        "    text = re.split('\\W+', text)\n",
        "    return text\n",
        "\n",
        "tdf_train['tokenized'] = tdf_train['Tweet_punct'].apply(lambda x: tokenization(x.lower()))\n",
        "\n",
        "stopword = nltk.corpus.stopwords.words('english')\n",
        "\n",
        "def remove_stopwords(text):\n",
        "    text = [word for word in text if word not in stopword]\n",
        "    return text\n",
        "    \n",
        "tdf_train['nonstop'] = tdf_train['tokenized'].apply(lambda x: remove_stopwords(x))\n",
        "\n",
        "ps = nltk.PorterStemmer()\n",
        "\n",
        "def stemming(text):\n",
        "    text = [ps.stem(word) for word in text]\n",
        "    return text\n",
        "\n",
        "tdf_train['stemmed'] = tdf_train['nonstop'].apply(lambda x: stemming(x))\n",
        "\n",
        "wn = nltk.WordNetLemmatizer()\n",
        "\n",
        "def lemmatizer(text):\n",
        "    text = [wn.lemmatize(word) for word in text]\n",
        "    return text\n",
        "\n",
        "tdf_train['lemmatized'] = tdf_train['nonstop'].apply(lambda x: lemmatizer(x))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:14: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:21: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:29: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:37: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zm6fVHVYWyYN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def clean_text(text):\n",
        "    text_lc = \"\".join([word.lower() for word in text if word not in string.punctuation]) # remove puntuation\n",
        "    text_rc = re.sub('[0-9]+', '', text_lc)\n",
        "    tokens = re.split('\\W+', text_rc)    # tokenization\n",
        "    text = [ps.stem(word) for word in tokens if word not in stopword]  # remove stopwords and stemming\n",
        "    return text"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "72q6hfb3XV38",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# # Import libraries\n",
        "# import pandas as pd\n",
        "# import numpy as np\n",
        "# import seaborn as sns\n",
        "# import matplotlib.pyplot as plt\n",
        "# from sklearn.feature_extraction.text import CountVectorizer\n",
        "# import nltk \n",
        "# import string\n",
        "# import re\n",
        "# %matplotlib inline\n",
        "\n",
        "# pd.set_option('display.max_colwidth', 100)\n",
        "# countVectorizer = CountVectorizer(analyzer=clean_text) \n",
        "# countVector = countVectorizer.fit_transform(tdf_train['text'])\n",
        "# print('{} Number of tweets has {} words'.format(countVector.shape[0], countVector.shape[1]))\n",
        "# #print(countVectorizer.get_feature_names("
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S2frsc1DZE5o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# count_vect_df = pd.DataFrame(countVector.toarray(), columns=countVectorizer.get_feature_names())\n",
        "# count_vect_df.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cs1UVb0VXeiO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_merge['Tweet_punct'] = test_merge['text'].apply(lambda x: remove_punct(x))\n",
        "test_merge['tokenized'] = test_merge['Tweet_punct'].apply(lambda x: tokenization(x.lower()))\n",
        "test_merge['nonstop'] = test_merge['tokenized'].apply(lambda x: remove_stopwords(x))\n",
        "test_merge['stemmed'] = test_merge['nonstop'].apply(lambda x: stemming(x))\n",
        "test_merge['lemmatized'] = test_merge['nonstop'].apply(lambda x: lemmatizer(x))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KesBPsoAcC0R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tdf_train.to_pickle(\"tdf_train.pkl\")\n",
        "tdf_train = pd.read_pickle(\"tdf_train.pkl\")\n",
        "test_merge.to_pickle(\"test_merge.pkl\")\n",
        "test_merge = pd.read_pickle(\"test_merge.pkl\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c7pPdOG4lyFY",
        "colab_type": "code",
        "outputId": "102c292e-40ec-4c0b-9c8f-e01fc299893b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        }
      },
      "source": [
        "tdf_train.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweet_id</th>\n",
              "      <th>text</th>\n",
              "      <th>emotion</th>\n",
              "      <th>Tweet_punct</th>\n",
              "      <th>tokenized</th>\n",
              "      <th>nonstop</th>\n",
              "      <th>stemmed</th>\n",
              "      <th>lemmatized</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0x376b20</td>\n",
              "      <td>People who post \"add me on #Snapchat\" must be ...</td>\n",
              "      <td>anticipation</td>\n",
              "      <td>People who post add me on Snapchat must be deh...</td>\n",
              "      <td>[people, who, post, add, me, on, snapchat, mus...</td>\n",
              "      <td>[people, post, add, snapchat, must, dehydrated...</td>\n",
              "      <td>[peopl, post, add, snapchat, must, dehydr, cuz...</td>\n",
              "      <td>[people, post, add, snapchat, must, dehydrated...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0x2d5350</td>\n",
              "      <td>@brianklaas As we see, Trump is dangerous to #...</td>\n",
              "      <td>sadness</td>\n",
              "      <td>brianklaas As we see Trump is dangerous to fre...</td>\n",
              "      <td>[brianklaas, as, we, see, trump, is, dangerous...</td>\n",
              "      <td>[brianklaas, see, trump, dangerous, freepress,...</td>\n",
              "      <td>[brianklaa, see, trump, danger, freepress, aro...</td>\n",
              "      <td>[brianklaas, see, trump, dangerous, freepress,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0x1cd5b0</td>\n",
              "      <td>Now ISSA is stalking Tasha üòÇüòÇüòÇ &lt;LH&gt;</td>\n",
              "      <td>fear</td>\n",
              "      <td>Now ISSA is stalking Tasha üòÇüòÇüòÇ LH</td>\n",
              "      <td>[now, issa, is, stalking, tasha, lh]</td>\n",
              "      <td>[issa, stalking, tasha, lh]</td>\n",
              "      <td>[issa, stalk, tasha, lh]</td>\n",
              "      <td>[issa, stalking, tasha, lh]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0x1d755c</td>\n",
              "      <td>@RISKshow @TheKevinAllison Thx for the BEST TI...</td>\n",
              "      <td>joy</td>\n",
              "      <td>RISKshow TheKevinAllison Thx for the BEST TIME...</td>\n",
              "      <td>[riskshow, thekevinallison, thx, for, the, bes...</td>\n",
              "      <td>[riskshow, thekevinallison, thx, best, time, t...</td>\n",
              "      <td>[riskshow, thekevinallison, thx, best, time, t...</td>\n",
              "      <td>[riskshow, thekevinallison, thx, best, time, t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0x2c91a8</td>\n",
              "      <td>Still waiting on those supplies Liscus. &lt;LH&gt;</td>\n",
              "      <td>anticipation</td>\n",
              "      <td>Still waiting on those supplies Liscus LH</td>\n",
              "      <td>[still, waiting, on, those, supplies, liscus, lh]</td>\n",
              "      <td>[still, waiting, supplies, liscus, lh]</td>\n",
              "      <td>[still, wait, suppli, liscu, lh]</td>\n",
              "      <td>[still, waiting, supply, liscus, lh]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   tweet_id  ...                                         lemmatized\n",
              "0  0x376b20  ...  [people, post, add, snapchat, must, dehydrated...\n",
              "1  0x2d5350  ...  [brianklaas, see, trump, dangerous, freepress,...\n",
              "2  0x1cd5b0  ...                        [issa, stalking, tasha, lh]\n",
              "3  0x1d755c  ...  [riskshow, thekevinallison, thx, best, time, t...\n",
              "4  0x2c91a8  ...               [still, waiting, supply, liscus, lh]\n",
              "\n",
              "[5 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1rPIvOmOgWIW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.naive_bayes import MultinomialNB \n",
        "from sklearn.metrics import accuracy_score \n",
        "from sklearn.naive_bayes import GaussianNB"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E8dqMspxmW1Z",
        "colab_type": "code",
        "outputId": "d748cdc6-1aa4-4f91-a75a-e8071c83d58d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "type(tdf_train['stemmed'])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "pandas.core.series.Series"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sj0evK8NpM_R",
        "colab_type": "code",
        "outputId": "c34bf86a-d4bc-48dc-9738-c591dd216ffe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 414
        }
      },
      "source": [
        "\n",
        "test_merge= test_merge[['tweet_id', 'stemmed', 'emotion']] \n",
        "test_merge\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweet_id</th>\n",
              "      <th>stemmed</th>\n",
              "      <th>emotion</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0x28cc61</td>\n",
              "      <td>[habbo, ive, seen, two, separ, colour, eleg, f...</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0x2db41f</td>\n",
              "      <td>[foxnew, kellyannepol, seriou, self, respect, ...</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>0x2466f6</td>\n",
              "      <td>[look, new, car, say, ladi, owner, mean, need,...</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>0x23f9e9</td>\n",
              "      <td>[cineworld, brave, fountain, park, show, per, ...</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>0x1fb4e1</td>\n",
              "      <td>[felt, like, total, dog, go, open, gym, migrai...</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1867495</th>\n",
              "      <td>0x2c4dc2</td>\n",
              "      <td>[, year, old, walk, astound, mum, look, bendi,...</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1867496</th>\n",
              "      <td>0x31be7c</td>\n",
              "      <td>[one, week, go, inspiringvolunteeraward, cant,...</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1867500</th>\n",
              "      <td>0x1ca58e</td>\n",
              "      <td>[got, caught, manga, hero, academia, dont, kno...</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1867515</th>\n",
              "      <td>0x35c8ba</td>\n",
              "      <td>[speak, spoken, make, hot, ass, music, lh]</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1867518</th>\n",
              "      <td>0x1d941b</td>\n",
              "      <td>[know, want, go, fuck, everyon, els, say, what...</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>411972 rows √ó 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         tweet_id                                            stemmed emotion\n",
              "0        0x28cc61  [habbo, ive, seen, two, separ, colour, eleg, f...        \n",
              "3        0x2db41f  [foxnew, kellyannepol, seriou, self, respect, ...        \n",
              "15       0x2466f6  [look, new, car, say, ladi, owner, mean, need,...        \n",
              "23       0x23f9e9  [cineworld, brave, fountain, park, show, per, ...        \n",
              "31       0x1fb4e1  [felt, like, total, dog, go, open, gym, migrai...        \n",
              "...           ...                                                ...     ...\n",
              "1867495  0x2c4dc2  [, year, old, walk, astound, mum, look, bendi,...        \n",
              "1867496  0x31be7c  [one, week, go, inspiringvolunteeraward, cant,...        \n",
              "1867500  0x1ca58e  [got, caught, manga, hero, academia, dont, kno...        \n",
              "1867515  0x35c8ba         [speak, spoken, make, hot, ass, music, lh]        \n",
              "1867518  0x1d941b  [know, want, go, fuck, everyon, els, say, what...        \n",
              "\n",
              "[411972 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q6Vk_p51oSwc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# tdf_train['stemmed'] = tdf_train['stemmed'].str.encode\n",
        "# tdf_train['stemmed'].head()\n",
        "# test_merge['stemmed'] = test_merge['stemmed'].str.encode"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dDSWh9zqPBr-",
        "colab_type": "code",
        "outputId": "7c217d32-fc12-4c8e-f153-9eb3fbe9963d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        }
      },
      "source": [
        "tdf_train.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweet_id</th>\n",
              "      <th>text</th>\n",
              "      <th>emotion</th>\n",
              "      <th>Tweet_punct</th>\n",
              "      <th>tokenized</th>\n",
              "      <th>nonstop</th>\n",
              "      <th>stemmed</th>\n",
              "      <th>lemmatized</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0x376b20</td>\n",
              "      <td>People who post \"add me on #Snapchat\" must be ...</td>\n",
              "      <td>anticipation</td>\n",
              "      <td>People who post add me on Snapchat must be deh...</td>\n",
              "      <td>[people, who, post, add, me, on, snapchat, mus...</td>\n",
              "      <td>[people, post, add, snapchat, must, dehydrated...</td>\n",
              "      <td>[peopl, post, add, snapchat, must, dehydr, cuz...</td>\n",
              "      <td>[people, post, add, snapchat, must, dehydrated...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0x2d5350</td>\n",
              "      <td>@brianklaas As we see, Trump is dangerous to #...</td>\n",
              "      <td>sadness</td>\n",
              "      <td>brianklaas As we see Trump is dangerous to fre...</td>\n",
              "      <td>[brianklaas, as, we, see, trump, is, dangerous...</td>\n",
              "      <td>[brianklaas, see, trump, dangerous, freepress,...</td>\n",
              "      <td>[brianklaa, see, trump, danger, freepress, aro...</td>\n",
              "      <td>[brianklaas, see, trump, dangerous, freepress,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0x1cd5b0</td>\n",
              "      <td>Now ISSA is stalking Tasha üòÇüòÇüòÇ &lt;LH&gt;</td>\n",
              "      <td>fear</td>\n",
              "      <td>Now ISSA is stalking Tasha üòÇüòÇüòÇ LH</td>\n",
              "      <td>[now, issa, is, stalking, tasha, lh]</td>\n",
              "      <td>[issa, stalking, tasha, lh]</td>\n",
              "      <td>[issa, stalk, tasha, lh]</td>\n",
              "      <td>[issa, stalking, tasha, lh]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0x1d755c</td>\n",
              "      <td>@RISKshow @TheKevinAllison Thx for the BEST TI...</td>\n",
              "      <td>joy</td>\n",
              "      <td>RISKshow TheKevinAllison Thx for the BEST TIME...</td>\n",
              "      <td>[riskshow, thekevinallison, thx, for, the, bes...</td>\n",
              "      <td>[riskshow, thekevinallison, thx, best, time, t...</td>\n",
              "      <td>[riskshow, thekevinallison, thx, best, time, t...</td>\n",
              "      <td>[riskshow, thekevinallison, thx, best, time, t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0x2c91a8</td>\n",
              "      <td>Still waiting on those supplies Liscus. &lt;LH&gt;</td>\n",
              "      <td>anticipation</td>\n",
              "      <td>Still waiting on those supplies Liscus LH</td>\n",
              "      <td>[still, waiting, on, those, supplies, liscus, lh]</td>\n",
              "      <td>[still, waiting, supplies, liscus, lh]</td>\n",
              "      <td>[still, wait, suppli, liscu, lh]</td>\n",
              "      <td>[still, waiting, supply, liscus, lh]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   tweet_id  ...                                         lemmatized\n",
              "0  0x376b20  ...  [people, post, add, snapchat, must, dehydrated...\n",
              "1  0x2d5350  ...  [brianklaas, see, trump, dangerous, freepress,...\n",
              "2  0x1cd5b0  ...                        [issa, stalking, tasha, lh]\n",
              "3  0x1d755c  ...  [riskshow, thekevinallison, thx, best, time, t...\n",
              "4  0x2c91a8  ...               [still, waiting, supply, liscus, lh]\n",
              "\n",
              "[5 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nCd3VXjsPUOI",
        "colab_type": "code",
        "outputId": "17e1b31f-c495-4e69-bcda-f171f14e7354",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 414
        }
      },
      "source": [
        "tdf_train_final= tdf_train[['tweet_id', 'stemmed', 'emotion']] \n",
        "tdf_train_final"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweet_id</th>\n",
              "      <th>stemmed</th>\n",
              "      <th>emotion</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0x376b20</td>\n",
              "      <td>[peopl, post, add, snapchat, must, dehydr, cuz...</td>\n",
              "      <td>anticipation</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0x2d5350</td>\n",
              "      <td>[brianklaa, see, trump, danger, freepress, aro...</td>\n",
              "      <td>sadness</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0x1cd5b0</td>\n",
              "      <td>[issa, stalk, tasha, lh]</td>\n",
              "      <td>fear</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0x1d755c</td>\n",
              "      <td>[riskshow, thekevinallison, thx, best, time, t...</td>\n",
              "      <td>joy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0x2c91a8</td>\n",
              "      <td>[still, wait, suppli, liscu, lh]</td>\n",
              "      <td>anticipation</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1455558</th>\n",
              "      <td>0x321566</td>\n",
              "      <td>[im, happi, nowond, name, show, happi, happysy...</td>\n",
              "      <td>joy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1455559</th>\n",
              "      <td>0x38959e</td>\n",
              "      <td>[everi, circumt, id, like, thank, almighti, je...</td>\n",
              "      <td>joy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1455560</th>\n",
              "      <td>0x2cbca6</td>\n",
              "      <td>[there, current, two, girl, walk, around, libr...</td>\n",
              "      <td>joy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1455561</th>\n",
              "      <td>0x24faed</td>\n",
              "      <td>[ah, corpor, life, date, lh, use, rel, anachro...</td>\n",
              "      <td>joy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1455562</th>\n",
              "      <td>0x34be8c</td>\n",
              "      <td>[bless, live, sundayvib, lh]</td>\n",
              "      <td>joy</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1455563 rows √ó 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         tweet_id  ...       emotion\n",
              "0        0x376b20  ...  anticipation\n",
              "1        0x2d5350  ...       sadness\n",
              "2        0x1cd5b0  ...          fear\n",
              "3        0x1d755c  ...           joy\n",
              "4        0x2c91a8  ...  anticipation\n",
              "...           ...  ...           ...\n",
              "1455558  0x321566  ...           joy\n",
              "1455559  0x38959e  ...           joy\n",
              "1455560  0x2cbca6  ...           joy\n",
              "1455561  0x24faed  ...           joy\n",
              "1455562  0x34be8c  ...           joy\n",
              "\n",
              "[1455563 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2A0qIgNhSFyf",
        "colab_type": "code",
        "outputId": "2ae4b7de-7b11-405d-a3fc-c4cf935f8122",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 414
        }
      },
      "source": [
        "test_merge"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweet_id</th>\n",
              "      <th>stemmed</th>\n",
              "      <th>emotion</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0x28cc61</td>\n",
              "      <td>[habbo, ive, seen, two, separ, colour, eleg, f...</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0x2db41f</td>\n",
              "      <td>[foxnew, kellyannepol, seriou, self, respect, ...</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>0x2466f6</td>\n",
              "      <td>[look, new, car, say, ladi, owner, mean, need,...</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>0x23f9e9</td>\n",
              "      <td>[cineworld, brave, fountain, park, show, per, ...</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>0x1fb4e1</td>\n",
              "      <td>[felt, like, total, dog, go, open, gym, migrai...</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1867495</th>\n",
              "      <td>0x2c4dc2</td>\n",
              "      <td>[, year, old, walk, astound, mum, look, bendi,...</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1867496</th>\n",
              "      <td>0x31be7c</td>\n",
              "      <td>[one, week, go, inspiringvolunteeraward, cant,...</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1867500</th>\n",
              "      <td>0x1ca58e</td>\n",
              "      <td>[got, caught, manga, hero, academia, dont, kno...</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1867515</th>\n",
              "      <td>0x35c8ba</td>\n",
              "      <td>[speak, spoken, make, hot, ass, music, lh]</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1867518</th>\n",
              "      <td>0x1d941b</td>\n",
              "      <td>[know, want, go, fuck, everyon, els, say, what...</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>411972 rows √ó 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         tweet_id                                            stemmed emotion\n",
              "0        0x28cc61  [habbo, ive, seen, two, separ, colour, eleg, f...        \n",
              "3        0x2db41f  [foxnew, kellyannepol, seriou, self, respect, ...        \n",
              "15       0x2466f6  [look, new, car, say, ladi, owner, mean, need,...        \n",
              "23       0x23f9e9  [cineworld, brave, fountain, park, show, per, ...        \n",
              "31       0x1fb4e1  [felt, like, total, dog, go, open, gym, migrai...        \n",
              "...           ...                                                ...     ...\n",
              "1867495  0x2c4dc2  [, year, old, walk, astound, mum, look, bendi,...        \n",
              "1867496  0x31be7c  [one, week, go, inspiringvolunteeraward, cant,...        \n",
              "1867500  0x1ca58e  [got, caught, manga, hero, academia, dont, kno...        \n",
              "1867515  0x35c8ba         [speak, spoken, make, hot, ass, music, lh]        \n",
              "1867518  0x1d941b  [know, want, go, fuck, everyon, els, say, what...        \n",
              "\n",
              "[411972 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Bguxb0qo92t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2eGTmgrXpHdq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# from sklearn.model_selection import train_test_split\n",
        "# V_train, V_test, z_train, z_test = train_test_split(X_train, y_train, random_state=0)\n",
        "# test_clf=Pipeline([\n",
        "#                 ('tfidf', TfidfVectorizer()),\n",
        "#                 ('nbc' , RandomForestClassifier(n_estimators=100, random_state=0)),\n",
        "#             ])\n",
        "# test_clf.fit(V_train, z_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rZDyT_r8junE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### TEST\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.gaussian_process import GaussianProcessClassifier\n",
        "from sklearn.gaussian_process.kernels import RBF\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
        "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "\n",
        "X_train = tdf_train_final['stemmed'].apply(lambda x: ' '.join(x))\n",
        "y_train = tdf_train_final['emotion']\n",
        "X_test = test_merge['stemmed'].apply(lambda x: ' '.join(x))\n",
        "# y_test = test_merge['emotion']\n",
        "\n",
        "clf=Pipeline([\n",
        "                ('tfidf', TfidfVectorizer()),\n",
        "                ('nbc' , LogisticRegression()),\n",
        "            ])\n",
        "\n",
        "clf.fit(X_train, y_train)\n",
        "y_pred = clf.predict(X_test)\n",
        "\n",
        "# pipeline...habogietry"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bIOuOrmFAZa4",
        "colab_type": "code",
        "outputId": "984eb224-6b98-44ca-ca61-9a45fc57a6b6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "y_pred"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['joy', 'sadness', 'joy', ..., 'anticipation', 'joy', 'joy'],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h37Ko993A01E",
        "colab_type": "code",
        "outputId": "331f892a-a746-47c7-9560-b638635192dc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "np.unique(y_pred)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['anger', 'anticipation', 'disgust', 'fear', 'joy', 'sadness',\n",
              "       'surprise', 'trust'], dtype='<U12')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fksJ5l0hAfr-",
        "colab_type": "code",
        "outputId": "8a16af24-0710-463e-b985-68e3a6228716",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 201
        }
      },
      "source": [
        "submission = pd.DataFrame({'id':test_merge['tweet_id'], 'emotion':y_pred})\n",
        "submission.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>emotion</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0x28cc61</td>\n",
              "      <td>joy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0x2db41f</td>\n",
              "      <td>joy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>0x2466f6</td>\n",
              "      <td>joy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>0x23f9e9</td>\n",
              "      <td>joy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>0x1fb4e1</td>\n",
              "      <td>joy</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          id emotion\n",
              "0   0x28cc61     joy\n",
              "3   0x2db41f     joy\n",
              "15  0x2466f6     joy\n",
              "23  0x23f9e9     joy\n",
              "31  0x1fb4e1     joy"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vyBKfvoEATTI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "export_csv = submission.to_csv ('result6.csv', index = False, header=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "npO27G7RbOkU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}